rm(list = ls())
try(dev.off())
dev.set(2)
plot.new()
shell("cls")
library(caret)
## SET working dir
work_dir<-"~/script_vecchi_coursera/machine_learning"
if(!file.exists(work_dir)){dir.create(work_dir)}
setwd("~/script_vecchi_coursera/machine_learning")
if(!file.exists("data")){dir.create("data")}
setwd("./data")
## GET DATA
url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url1<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_name<-"pml-training.csv"
test_name<-"pml-testing.csv"
list.files(pattern = )
if(!file.exists(train_name)){download.file(url, destfile = train_name)}
if(!file.exists(test_name)){download.file(url, destfile = test_name)}
train <- read.csv("pml-training.csv",na.strings = c("NA",""))
test <- read.csv("pml-testing.csv",na.strings = c("NA",""))
tmp<-colSums(is.na(train))
train<-train[,tmp==0]
dim(train)
train<-train[,-c(1:7)]
test<-test[,tmp==0]
dim(test)
test<-test[,-c(1:7)]
#split the train set
tmp<-createDataPartition(train$classe,p=0.75,list = FALSE)
train_data<-train[tmp,]
valid_data<-train[-tmp,]
rm(list = ls())
try(dev.off())
dev.set(2)
plot.new()
shell("cls")
library(caret)
## SET working dir
work_dir<-"~/script_vecchi_coursera/machine_learning"
if(!file.exists(work_dir)){dir.create(work_dir)}
setwd("~/script_vecchi_coursera/machine_learning")
if(!file.exists("data")){dir.create("data")}
setwd("./data")
## GET DATA
url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url1<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_name<-"pml-training.csv"
test_name<-"pml-testing.csv"
list.files(pattern = )
if(!file.exists(train_name)){download.file(url, destfile = train_name)}
if(!file.exists(test_name)){download.file(url, destfile = test_name)}
train <- read.csv("pml-training.csv",na.strings = c("NA",""))
tmp<-colSums(is.na(train))
train<-train[,tmp==0]
dim(train)
train<-train[,-c(1:7)]
test<-test[,tmp==0]
dim(test)
tmp<-colSums(is.na(train))
train<-train[,tmp==0]
dim(train)
train<-train[,-c(1:7)]
#split the train set
tmp<-createDataPartition(train$classe,p=0.75,list = FALSE)
train_data<-train[tmp,]
valid_data<-train[-tmp,]
rm(url,url1,work_dir,test_name)
rm(url,url1,work_dir,test_name,train)
rm(url,url1,work_dir,test_name,train,tmp)
rm(list = ls())
try(dev.off())
dev.set(2)
plot.new()
shell("cls")
library(caret)
## SET working dir
work_dir<-"~/script_vecchi_coursera/machine_learning"
if(!file.exists(work_dir)){dir.create(work_dir)}
setwd("~/script_vecchi_coursera/machine_learning")
if(!file.exists("data")){dir.create("data")}
setwd("./data")
## GET DATA
url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url1<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_name<-"pml-training.csv"
test_name<-"pml-testing.csv"
list.files(pattern = )
if(!file.exists(train_name)){download.file(url, destfile = train_name)}
if(!file.exists(test_name)){download.file(url, destfile = test_name)}
train <- read.csv("pml-training.csv",na.strings = c("NA",""))
tmp<-colSums(is.na(train))
train<-train[,tmp==0]
dim(train)
train<-train[,-c(1:7)]
#split the train set
tmp<-createDataPartition(train$classe,p=0.75,list = FALSE)
train_data<-train[tmp,]
valid_data<-train[-tmp,]
rm(url,url1,work_dir,test_name,train,tmp)
cor_matrix<-cor(train_data[,-53])
cor_matrix<-abs(cor(train_data[,-53]))
corrplot(cor_matrix,type="square")
?corrplot
library(corrplot)
cor_matrix<-abs(cor(train_data[,-53]))
corrplot(cor_matrix,type="square")
?corrplot
corrplot(cor_matrix,method="square")
corrplot(cor_matrix,method="square",tl.cex=0.6)
PCA_Comp<-prcomp(train_data[,-53],scale. = TRUE)
std_dev <- PCA_Comp$sdev
PCA_var <- std_dev^2
prop_varex <- PCA_var/sum(PCA_var)
plot(cumsum(prop_varex), xlab = "Principal Component",ylab = "Cumulative Proportion of Variance Explained",type = "b")
abline(h=0.975,col='red',v=30)
sum(prop_varex[1:30])
PCA_Comp<-preProcess(train_data,method = c("center","scale","pca"),thresh = 0.99)
PCA_Comp
rm(cor_matrix,PCA_var,prop_varex,std_dev)
train_PCA<-predict(PCA_Comp,train_data)
View(train_PCA)
gc()
library(doParallel)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)
model <- train(y ~ ., data = train_PCA, method = "rf")
model <- train(classe ~ ., data = train_PCA, method = "rf")
stopCluster(cl)
gc()
library(doParallel)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
model <- train(classe ~ ., data = train_PCA, method = "rf")
valid_PCA<-predict(PCA_Comp,valid_data)
stopCluster(cl)
confusionMatrix(valid_PCA,valid_data$classe)
model
RF<-predict(model,valid_data)
valid_PCA<-predict(PCA_Comp,valid_data)
predict(model,valid_PCA)
confusionMatrix(predict(model,valid_PCA),valid_PCA$classe)
valid_RF<-predict(model,newdata=valid_PCA)
confusionMatrix(valid_RF),valid_PCA$classe)
valid_RF<-predict(model,newdata=valid_PCA)
confusionMatrix(valid_RF),valid_PCA$classe)
confusionMatrix(valid_RF,valid_PCA$classe)
stopCluster(cl)
gc()
library(doParallel)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
model_2<-train(classe ~ .,data = train_data,method = "rf",preprocessing="pca")
valid_RF2<-predict(model2,newdata=valid_PCA)
confusionMatrix(valid_RF2,valid_PCA$classe)
valid_RF2<-predict(model2,newdata=valid_PCA)
valid_RF2<-predict(model_2,newdata=valid_PCA)
confusionMatrix(valid_RF2,valid_data$classe)
valid_RF2<-predict(model_2,newdata=valid_data)
confusionMatrix(valid_RF2,valid_data$classe)
#final
test <- read.csv("pml-testing.csv",na.strings = c("NA",""))
tmp<-colSums(is.na(train))
test<-test[,tmp==0]
dim(test)
test<-test[,-c(1:7)]
dim(test)
tmp<-colSums(is.na(test))
test<-test[,tmp==0]
dim(test)
#final
test <- read.csv("pml-testing.csv",na.strings = c("NA",""))
tmp<-colSums(is.na(test))
test<-test[,tmp==0]
dim(test)
test<-test[,-c(1:7)]
predict(model_2,test)
predict_test<-predict(model_2,test)
predict_test
predict_test<-predict(model_2,test,type="class")
test_PCA<-predict(PCA_Comp,test)
predict_test<-predict(model,test_PCA,type="class")
predict_test<-predict(model,test_PCA)
predict_test
confusionMatrix(valid_RF2,valid_data$classe,type="class")
predict_test<-as.vector(predict(model,test_PCA))
predict_test
View(test)
library(ggplot2)
#Import the data and clean it up a bit
pmlimport <- read.csv("pml-training.csv", header = TRUE, sep = ",")
rm(pmlimport)
save.image("~/script_vecchi_coursera/machine_learning/data/test.RData")
#Start by loading the necessary libraries
library(caret)
library(ggplot2)
#Import the data and clean it up a bit
pmlimport <- read.csv("pml-training.csv", header = TRUE, sep = ",")
pmldata <- pmlimport[,sapply(seq(1:length(colnames(pmlimport))),
function(i) is.numeric(pmlimport[,i])) &
sapply(seq(1:length(colnames(pmlimport))),
function(i) sum(is.na(pmlimport[,i]))==0)]
View(pmldata)
#Add the classe (result) and user-name back into the data frame
#pmldata$user_name <- pmlimport$user_name
pmldata$classe <- pmlimport$classe
View(pmldata)
#Remove the timestamps, window numbers and index
pmldata <- pmldata[,!(names(pmldata) %in%
c("raw_timestamp_part_1","raw_timestamp_part_2",
"num_window","X"))]
#Remove the original import to free up space
rm(pmlimport)
#First we split the training data into training and test sets, 75/25
set.seed(1234)
inTrain <- createDataPartition(y=pmldata$classe, p=0.75, list = FALSE)
pmltraining <- pmldata[inTrain,]
pmltesting <- pmldata[-inTrain,]
#We will use k-fold cross-validation on the training set, with 5 folds
trainfolds <- createFolds(y=pmltraining$classe, k = 5, list = TRUE, returnTrain = TRUE)
testfolds <- createFolds(y=pmltraining$classe, k = 5, list = TRUE, returnTrain = FALSE)
#Use the different folds for checking the in-sample error
for (i in 1:length(trainfolds)){
mod <- train(classe ~ ., data=pmltraining[trainfolds[[i]],],
preProcess = c("center", "scale"), method = "qda")
pred <- predict(mod, pmltraining[testfolds[[i]],])
print(confusionMatrix(pred,pmltraining[testfolds[[i]],]$classe))
}
#Apply the model to the test set just once, to estimate the out-of-sample error
finalmod <- train(classe ~ ., data=pmltraining,
preProcess = c("center", "scale"), method = "qda")
finalpred <- predict(finalmod, pmltesting)
print(confusionMatrix(finalpred,pmltesting$classe))
pmlfinalimport <- read.csv("pml-testing.csv", header = TRUE, sep = ",")
pmlfinaldata <- pmlfinalimport[,sapply(seq(1:length(colnames(pmlfinalimport))),
function(i) is.numeric(pmlfinalimport[,i])) &
sapply(seq(1:length(colnames(pmlfinalimport))),
function(i) sum(is.na(pmlfinalimport[,i]))==0)]
View(pmlfinaldata)
#Add the classe (result) and user-name back into the data frame
#pmldata$user_name <- pmlimport$user_name
pmlfinaldata$classe <- pmlfinalimport$classe
#Remove the timestamps, window numbers and index
pmlfinaltest <- pmlfinaldata[,!(names(pmlfinaldata) %in%
c("raw_timestamp_part_1","raw_timestamp_part_2",
"num_window","X"))]
submitpred <- predict(finalmod, pmlfinaltest)
answers <- as.vector(submitpred)
View(pmlfinaldata)
library(caret)
library(corrplot)
library(randomForest)
dat = read.csv("pml-training.csv", na.strings=c("", "NA"))
#Clean Data - Remove NaN and other cols - timestamp etc
dat = dat[8:length(dat)]
remCol =  colSums(is.na(dat))
dat = dat[,remCol == 0]
#Create training and testing data
inTrain = createDataPartition(dat$classe, p = 3/4)[[1]]
training = dat[ inTrain,]
validation = dat[-inTrain,]
# plot a correlation matrix
correlMatrix <- cor(training[, -length(training)])
corrplot(correlMatrix, type = "lower", tl.cex = 0.8)
load("~/script_vecchi_coursera/machine_learning/data/test.RData")
print(model)
rfResVal = predict(model,valid_data)
#Get an estimate of how well the model has been trained
print ("RF - Cross Validataion");
print(rfResVal)
rfResVal = predict(model,valid_data)
confusionMatrix(valid_data$classe, train_PCA)
confusionMatrix(valid_data$classe, valid_PCA)
rfResVal = predict(model,valid_data)
rfResVal = predict(model,valid_PCA)
#Get an estimate of how well the model has been trained
print ("RF - Cross Validataion");
print(rfResVal)
confusionMatrix(valid_data$classe, valid_PCA)
confusionMatrix(valid_data$classe, valid_PCA)
confusionMatrix(valid_PCA$classe, valid_PCA)
confusionMatrix(valid_PCA$classe, rfResVal)
accuracy = confusionMatrix(validation$classe, rfResVal)$overall['Accuracy']
accuracy = confusionMatrix(valid_PCA$classe, rfResVal)$overall['Accuracy']
outOfSampleError = (1 - accuracy) * 100
print("Out of sample error estimation: "); print(round(outOfSampleError, digits = 2))
# Fit the model to the new data
answers = predict(model_2,test)
print (answers)
#Write the results to files
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
library(caret)
library(corrplot)
library(randomForest)
set.seed(33355)
dat = read.csv("pml-training.csv", na.strings=c("", "NA"))
#Clean Data - Remove NaN and other cols - timestamp etc
dat = dat[8:length(dat)]
remCol =  colSums(is.na(dat))
dat = dat[,remCol == 0]
#Create training and testing data
inTrain = createDataPartition(dat$classe, p = 3/4)[[1]]
training = dat[ inTrain,]
validation = dat[-inTrain,]
# plot a correlation matrix
correlMatrix <- cor(training[, -length(training)])
corrplot(correlMatrix, type = "lower", tl.cex = 0.8)
gc()
#Compute Rantdom Forest with PCA to remove corelations
randomForestFit <- randomForest(classe~., data=training, preprocessing="pca")
print(model)
print(randomForestFit)
rfResVal = predict(randomForestFit,validation)
#Get an estimate of how well the model has been trained
print ("RF - Cross Validataion");
print(rfResVal)
confusionMatrix(validation$classe, rfResVal)
accuracy = confusionMatrix(validation$classe, rfResVal)$overall['Accuracy']
outOfSampleError = (1 - accuracy) * 100
print("Out of sample error estimation: "); print(round(outOfSampleError, digits = 2))
# Application of the model to new data set
testingFinal = read.csv("pml-testing.csv", na.strings=c("", "NA"))
testingFinal = testingFinal[8:length(testingFinal)]
testingFinal = testingFinal[,remCol == 0]
# Fit the model to the new data
answers = predict(randomForestFit,testingFinal)
print (answers)
#Write the results to files
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
rm(list = ls())
try(dev.off())
dev.set(2)
plot.new()
shell("cls")
library(caret)
library(randomForest)
## SET working dir
work_dir<-"~/script_vecchi_coursera/machine_learning"
if(!file.exists(work_dir)){dir.create(work_dir)}
setwd("~/script_vecchi_coursera/machine_learning")
if(!file.exists("data")){dir.create("data")}
setwd("./data")
## GET DATA
url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url1<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_name<-"pml-training.csv"
test_name<-"pml-testing.csv"
list.files(pattern = )
if(!file.exists(train_name)){download.file(url, destfile = train_name)}
if(!file.exists(test_name)){download.file(url1, destfile = test_name)}
train <- read.csv("pml-training.csv",na.strings = c("NA",""))
tmp<-colSums(is.na(train))
train<-train[,tmp==0]
dim(train)
train<-train[,-c(1:7)]
#split the train set
tmp<-createDataPartition(train$classe,p=0.75,list = FALSE)
train_data<-train[tmp,]
valid_data<-train[-tmp,]
rm(url,url1,work_dir,test_name,train,tmp)
library(corrplot)
cor_matrix<-abs(cor(train_data[,-53]))
corrplot(cor_matrix,method="square",tl.cex=0.6)
PCA_Comp<-prcomp(train_data[,-53],scale. = TRUE)
std_dev <- PCA_Comp$sdev
PCA_var <- std_dev^2
prop_varex <- PCA_var/sum(PCA_var)
rm(cor_matrix,PCA_var,prop_varex,std_dev)
plot(cumsum(prop_varex), xlab = "Principal Component",ylab = "Cumulative Proportion of Variance Explained",type = "b")
abline(h=0.975,col='red',v=30)
sum(prop_varex[1:30])
PCA_Comp<-preProcess(train_data,method = c("center","scale","pca"),thresh = 0.99)
train_PCA<-predict(PCA_Comp,train_data)
valid_PCA<-predict(PCA_Comp,valid_data)
gc()
library(doParallel)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
model<-randomForest(classe ~ .,data = train_PCA,method = "rf")
gc()
model<-randomForest(classe ~ .,data = train_PCA,method = "rf")
gc()
model_2<-randomForest(classe ~ .,data = train_data,method = "rf",preprocessing="pca")
library(caret)
library(corrplot)
library(randomForest)
set.seed(33355)
dat = read.csv("pml-training.csv", na.strings=c("", "NA"))
#Clean Data - Remove NaN and other cols - timestamp etc
dat = dat[8:length(dat)]
remCol =  colSums(is.na(dat))
dat = dat[,remCol == 0]
#Create training and testing data
inTrain = createDataPartition(dat$classe, p = 3/4)[[1]]
training = dat[ inTrain,]
library(caret)
library(corrplot)
library(randomForest)
set.seed(33355)
dat = read.csv("pml-training.csv", na.strings=c("", "NA"))
#Clean Data - Remove NaN and other cols - timestamp etc
dat = dat[8:length(dat)]
remCol =  colSums(is.na(dat))
dat = dat[,remCol == 0]
#Create training and testing data
inTrain = createDataPartition(dat$classe, p = 3/4)[[1]]
training = dat[ inTrain,]
validation = dat[-inTrain,]
# plot a correlation matrix
correlMatrix <- cor(training[, -length(training)])
corrplot(correlMatrix, type = "lower", tl.cex = 0.8)
#Compute Rantdom Forest with PCA to remove corelations
randomForestFit <- randomForest(classe~., data=training, preprocessing="pca")
rm(list = ls())
try(dev.off())
dev.set(2)
plot.new()
shell("cls")
library(caret)
library(randomForest)
## SET working dir
work_dir<-"~/script_vecchi_coursera/machine_learning"
if(!file.exists(work_dir)){dir.create(work_dir)}
setwd("~/script_vecchi_coursera/machine_learning")
if(!file.exists("data")){dir.create("data")}
setwd("./data")
## GET DATA
url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url1<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_name<-"pml-training.csv"
test_name<-"pml-testing.csv"
list.files(pattern = )
if(!file.exists(train_name)){download.file(url, destfile = train_name)}
if(!file.exists(test_name)){download.file(url1, destfile = test_name)}
train <- read.csv("pml-training.csv",na.strings = c("NA",""))
tmp<-colSums(is.na(train))
train<-train[,tmp==0]
dim(train)
train<-train[,-c(1:7)]
#split the train set
tmp<-createDataPartition(train$classe,p=0.75,list = FALSE)
train_data<-train[tmp,]
valid_data<-train[-tmp,]
rm(url,url1,work_dir,test_name,train,tmp)
library(corrplot)
cor_matrix<-abs(cor(train_data[,-53]))
corrplot(cor_matrix,method="square",tl.cex=0.6)
PCA_Comp<-prcomp(train_data[,-53],scale. = TRUE)
std_dev <- PCA_Comp$sdev
PCA_var <- std_dev^2
prop_varex <- PCA_var/sum(PCA_var)
rm(cor_matrix,PCA_var,prop_varex,std_dev)
plot(cumsum(prop_varex), xlab = "Principal Component",ylab = "Cumulative Proportion of Variance Explained",type = "b")
abline(h=0.975,col='red',v=30)
PCA_Comp<-prcomp(train_data[,-53],scale. = TRUE)
std_dev <- PCA_Comp$sdev
PCA_var <- std_dev^2
prop_varex <- PCA_var/sum(PCA_var)
rm(cor_matrix,PCA_var,std_dev)
plot(cumsum(prop_varex), xlab = "Principal Component",ylab = "Cumulative Proportion of Variance Explained",type = "b")
abline(h=0.975,col='red',v=30)
sum(prop_varex[1:30])
rm(prop_varex)
PCA_Comp<-preProcess(train_data,method = c("center","scale","pca"),thresh = 0.99)
train_PCA<-predict(PCA_Comp,train_data)
valid_PCA<-predict(PCA_Comp,valid_data)
gc()
library(doParallel)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
model<-randomForest(classe ~ .,data = train_PCA,method = "rf")
load("~/script_vecchi_coursera/machine_learning/data/test.RData")
valid_RF<-predict(model,newdata=valid_PCA)
valid_RF2<-predict(model_2,newdata=valid_data)
confusionMatrix(valid_RF,valid_PCA$classe)
confusionMatrix(valid_RF2,valid_data$classe)
stopCluster(cl)
#final
test <- read.csv("pml-testing.csv",na.strings = c("NA",""))
tmp<-colSums(is.na(test))
test<-test[,tmp==0]
dim(test)
test<-test[,-c(1:7)]
test_PCA<-predict(PCA_Comp,test)
predict_test<-as.vector(predict(model,test_PCA))
predict_test
predict_test<-predict(model_2,test)
predict_test
predict_test<-predict(model,test_PCA)
predict_test<-predict(model,test_PCA)
predict_test
save.image("~/script_vecchi_coursera/machine_learning/data/test.RData")
